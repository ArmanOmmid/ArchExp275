{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from models.pointnet import PointNet, TNet\n",
    "from models.modules import SpecialEuclideanGeodesicLoss\n",
    "\n",
    "from runners.experiment import run_epoch\n",
    "\n",
    "from torchinfo import summary\n",
    "\n",
    "def _R(theta, phi, psi, N):\n",
    "    return (torch.tensor([\n",
    "        [np.cos(theta), -np.sin(theta), 0],\n",
    "        [np.sin(theta), np.cos(theta), 0],\n",
    "        [0, 0, 1]\n",
    "    ]) @ torch.tensor([\n",
    "        [np.cos(phi), 0, np.sin(phi)],\n",
    "        [0, 1, 0],\n",
    "        [-np.sin(phi), 0, np.cos(phi)]\n",
    "    ]) @ torch.tensor([\n",
    "        [1, 0, 0],\n",
    "        [0, np.cos(psi), -np.sin(psi)],\n",
    "        [0, np.sin(psi), np.cos(psi)]\n",
    "    ])).unsqueeze(0).float().repeat(N, 1, 1)\n",
    "\n",
    "def _T(x, y, z, N):\n",
    "    return torch.tensor([[x], [y], [z]]).unsqueeze(0).float().repeat(N, 1, 1)\n",
    "\n",
    "def RT(angles, translations, N):\n",
    "    r = _R(*angles, N)\n",
    "    t = _T(*translations, N)\n",
    "    return torch.cat((r, t), dim=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 159])\n",
      "torch.Size([2, 1024])\n",
      "torch.Size([2, 3, 159])\n",
      "torch.Size([2, 64, 159])\n",
      "torch.Size([2, 1024])\n",
      "torch.Size([2, 64, 159])\n",
      "torch.Size([2, 128, 159])\n",
      "torch.Size([2, 1024, 1])\n",
      "torch.Size([2, 1024, 1])\n",
      "torch.Size([2, 64, 159])\n",
      "torch.Size([2, 1024, 1])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (2048x2 and 1024x512)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/armanommid/Code/CSE/CSE275/HW2/XSwinDiffusion/pointnet.ipynb Cell 2\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/armanommid/Code/CSE/CSE275/HW2/XSwinDiffusion/pointnet.ipynb#W1sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m torch\u001b[39m.\u001b[39mdiagonal(b, dim1\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, dim2\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\u001b[39m.\u001b[39msum(\u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/armanommid/Code/CSE/CSE275/HW2/XSwinDiffusion/pointnet.ipynb#W1sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39m# model.eval()\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/armanommid/Code/CSE/CSE275/HW2/XSwinDiffusion/pointnet.ipynb#W1sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m model(x)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Code/CSE/CSE275/HW2/XSwinDiffusion/models/pointnet.py:147\u001b[0m, in \u001b[0;36mPointNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[39mprint\u001b[39m(features_broadcasted\u001b[39m.\u001b[39mshape)\n\u001b[1;32m    145\u001b[0m x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat((x, features_broadcasted), dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m--> 147\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfc(x)\n\u001b[1;32m    149\u001b[0m \u001b[39m# x = self.pose(x)\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \n\u001b[1;32m    151\u001b[0m \u001b[39m# x = x.view(-1, 3, 4)\u001b[39;00m\n\u001b[1;32m    153\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (2048x2 and 1024x512)"
     ]
    }
   ],
   "source": [
    "SHAPE = 159, 3\n",
    "B = 2\n",
    "\n",
    "LR = 0.0001\n",
    "WD = 0.0001\n",
    "\n",
    "model = PointNet()\n",
    "criterion = SpecialEuclideanGeodesicLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR, weight_decay=WD)\n",
    "\n",
    "x = torch.ones((B, *SHAPE))\n",
    "\n",
    "angles = 0.1, 0.1, 0.1\n",
    "translations = 0.1, 0.2, 0.3\n",
    "\n",
    "y = RT(angles, translations, B)\n",
    "\n",
    "# print(y[0])\n",
    "\n",
    "b = RT((0, 0, 0), (0, 0, 0), 4)[:, :3, :3]\n",
    "\n",
    "\n",
    "torch.diagonal(b, dim1=1, dim2=2).sum(1)\n",
    "\n",
    "# model.eval()\n",
    "\n",
    "model(x)\n",
    "\n",
    "# for _ in range(1000):\n",
    "#     optimizer.zero_grad()\n",
    "#     outputs = model(x)\n",
    "#     loss = criterion(outputs, y)\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "\n",
    "# model(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.9900, -0.0894,  0.1088,  0.1000],\n",
      "         [ 0.0993,  0.9910, -0.0894,  0.2000],\n",
      "         [-0.0998,  0.0993,  0.9900,  0.3000]]])\n"
     ]
    }
   ],
   "source": [
    "print(y)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
