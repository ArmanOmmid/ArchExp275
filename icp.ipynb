{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import trimesh\n",
    "import open3d\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from pose_estimation.icp import icp\n",
    "from pose_estimation import PoseData, PoseDataNPZ, PoseDataNPZTorch, COLOR_PALETTE\n",
    "from pose_estimation.utils import back_project, show_points, compare_points, compute_rre, compute_rte, \\\n",
    "    crop_and_resize, crop_and_resize_multiple\n",
    "\n",
    "WORKDIR = f\"{os.getcwd()}/..\"\n",
    "DATA_FOLDER = os.path.join(WORKDIR, \"data_folder\")\n",
    "\n",
    "MODELS_PATH = os.path.join(DATA_FOLDER, \"models\")\n",
    "TRAIN_PATH = os.path.join(DATA_FOLDER, \"training_data\")\n",
    "TEST_PATH = os.path.join(DATA_FOLDER, \"testing_data\")\n",
    "\n",
    "TRAIN_NPZ_PATH = os.path.join(DATA_FOLDER, \"dataset_npz\")\n",
    "TEST_NPZ_PATH = os.path.join(DATA_FOLDER, \"dataset_npz_test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_banana = trimesh.load(f\"{DATA_FOLDER}/banana.source.ply\").vertices\n",
    "target_banana = trimesh.load(f\"{DATA_FOLDER}/banana.target.ply\").vertices\n",
    "gt_banana = np.loadtxt(f\"{DATA_FOLDER}/banana.pose.txt\")\n",
    "\n",
    "RUN_ICP_SANITY = False\n",
    "if RUN_ICP_SANITY:\n",
    "    iterations = 20\n",
    "    attempts = 10\n",
    "    # Visualization\n",
    "    T = icp(source_banana, target_banana, attempts=10)\n",
    "    rre = np.rad2deg(compute_rre(T[:3, :3], gt_banana[:3, :3]))\n",
    "    rte = compute_rte(T[:3, 3], gt_banana[:3, 3])\n",
    "    print(f\"rre={rre}, rte={rte}\")\n",
    "    compare_points(source_banana @ T[:3, :3].T + T[:3, 3], target_banana)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = PoseData(TRAIN_PATH, MODELS_PATH)\n",
    "\n",
    "scene = data[2, 1, 1]\n",
    "rgb = scene[\"color\"]()\n",
    "depth = scene[\"depth\"]()\n",
    "label = scene[\"label\"]()\n",
    "meta = scene[\"meta\"]\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(rgb)\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(depth)\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(COLOR_PALETTE[label])  # draw colorful segmentation\n",
    "\n",
    "mask = label == np.unique(label)[0]\n",
    "target_size = (432, 768)\n",
    "margin = 8\n",
    "aspect_ratio = True\n",
    "mask_fill = False\n",
    "\n",
    "(rgb_cr, depth_cr, label_cr, mask_cr), scale, translate = crop_and_resize_multiple(\n",
    "    (rgb, depth, COLOR_PALETTE[label], mask), mask, target_size=target_size, margin=margin, \n",
    "    aspect_ratio=aspect_ratio, mask_fill=mask_fill)\n",
    "\n",
    "\n",
    "# print(depth[mask][:200])\n",
    "# print(depth_cr[mask_cr][:200])\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(rgb_cr)\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(depth_cr)\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(label_cr)  # draw colorful segmentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_ICP = True\n",
    "if TEST_ICP:\n",
    "\n",
    "    selection = 3, 1, 44\n",
    "    scene = data[selection]\n",
    "\n",
    "\n",
    "    rgb = scene[\"color\"]() * 255\n",
    "    depth = scene[\"depth\"]() / 1000\n",
    "    label = scene[\"label\"]()\n",
    "    meta = scene[\"meta\"]\n",
    "\n",
    "    item = 0\n",
    "    obj_id = meta[\"object_ids\"][item]\n",
    "    scale, translate = None, None\n",
    "\n",
    "    MAX_SAMPLES = 1_000\n",
    "    mask = label == obj_id\n",
    "    target_size = (144, 256)\n",
    "    margin = 12\n",
    "    aspect_ratio = True\n",
    "    mask_fill = False\n",
    "\n",
    "    (rgb, depth, mask), scale, translate = crop_and_resize_multiple(\n",
    "        (rgb, depth, mask), mask, target_size=target_size, margin=margin, \n",
    "        aspect_ratio=aspect_ratio, mask_fill=mask_fill)\n",
    "    \n",
    "    print(scale, translate)\n",
    "\n",
    "    target_pcd, mask_indices = back_project(depth, meta, mask, (scale, translate), samples=MAX_SAMPLES)\n",
    "\n",
    "    print(mask_indices.shape)\n",
    "\n",
    "    print(len(target_pcd))\n",
    "\n",
    "    mesh = data.get_mesh(obj_id)\n",
    "    source_pcd, faces = trimesh.sample.sample_surface(mesh, MAX_SAMPLES)\n",
    "\n",
    "    source_pcd = source_pcd * meta[\"scales\"][obj_id]\n",
    "    target_pcd = target_pcd # / meta[\"scales\"][obj_id] # Back Projected\n",
    "\n",
    "    print(meta[\"object_names\"])\n",
    "\n",
    "    camera_scale = 0.2\n",
    "    camera_translate = np.mean(target_pcd, axis=0)\n",
    "\n",
    "    attempts = 10\n",
    "    # Visualization\n",
    "    T = icp(source_pcd, target_pcd, attempts=attempts)\n",
    "\n",
    "    print(T)\n",
    "    gt_T = meta[\"poses_world\"][obj_id]\n",
    "    print(gt_T)\n",
    "    print(\"\")\n",
    "\n",
    "    rre = np.rad2deg(compute_rre(T[:3, :3], gt_T[:3, :3]))\n",
    "    rte = compute_rte(T[:3, 3], gt_T[:3, 3])\n",
    "    print(f\"rre={rre}, rte={rte}\")\n",
    "\n",
    "    compare_points(source_pcd @ T[:3, :3].T + T[:3, 3], target_pcd, scale=camera_scale, translate=camera_translate)\n",
    "\n",
    "    # These are individual plots and will also point at the origin (stray points)\n",
    "    compare_points(source_pcd @ T[:3, :3].T + T[:3, 3], np.zeros((1, 3)), scale=camera_scale, translate=camera_translate)\n",
    "    compare_points(np.zeros((1, 3)), target_pcd, scale=camera_scale, translate=camera_translate)\n",
    "\n",
    "    compare_points(source_pcd @ gt_T[:3, :3].T + gt_T[:3, 3], target_pcd,  scale=camera_scale, translate=camera_translate)\n",
    "\n",
    "assert 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pose_estimation import draw_projected_box3d\n",
    "\n",
    "poses_world = np.array([meta['poses_world'][idx] for idx in meta['object_ids']])\n",
    "box_sizes = np.array([meta['extents'][idx] * meta['scales'][idx] for idx in meta['object_ids']])\n",
    "\n",
    "boxed_image = np.array(rgb)\n",
    "for i in range(len(poses_world)):\n",
    "    draw_projected_box3d(\n",
    "        boxed_image, poses_world[i][:3,3], box_sizes[i], poses_world[i][:3, :3], meta['extrinsic'], meta['intrinsic'],\n",
    "        thickness=2)\n",
    "\n",
    "Image.fromarray((boxed_image * 255).astype(np.uint8))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ICP_RUN = True\n",
    "if ICP_RUN:\n",
    "    data = PoseData(TEST_PATH, MODELS_PATH)\n",
    "\n",
    "    MESH_SAMPLES = None\n",
    "    ICP_ATTEMPTS = 10\n",
    "\n",
    "    results = {}\n",
    "    print(len(data))\n",
    "    for i, key in enumerate(data.keys()):\n",
    "\n",
    "        print(i, key)\n",
    "\n",
    "        l, s, v = key\n",
    "\n",
    "        scene = data[key]\n",
    "\n",
    "        rgb = scene[\"color\"]() * 255\n",
    "        depth = scene[\"depth\"]() / 1000\n",
    "        label = scene[\"label\"]()\n",
    "        meta = scene[\"meta\"]\n",
    "        \n",
    "        back_projection = back_project(depth, meta)\n",
    "\n",
    "        world_frames = [None] * 79\n",
    "\n",
    "        object_ids = [object_id for object_id in np.unique(label) if object_id < 79]\n",
    "\n",
    "        for object_id in object_ids:\n",
    "\n",
    "            indices = np.where(label == object_id)\n",
    "            obj_pnts = back_projection[indices]\n",
    "            obj_rgb = rgb[indices]\n",
    "\n",
    "            mesh = data.get_mesh(object_id)\n",
    "            source_pcd, faces = trimesh.sample.sample_surface(mesh, len(obj_pnts) if MESH_SAMPLES in [-1, 0, None, False] else MESH_SAMPLES)\n",
    "\n",
    "            source_pcd = source_pcd * meta[\"scales\"][object_id]\n",
    "            target_pcd = obj_pnts\n",
    "\n",
    "            T = icp(source_pcd, target_pcd, attempts=ICP_ATTEMPTS)\n",
    "\n",
    "            world_frames[object_id] = T.tolist()\n",
    "\n",
    "            results[f\"{l}-{s}-{v}\"] = {\"poses_world\" : world_frames}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"results.json\", \"w\") as f:\n",
    "    json.dump(results, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 ('cse291i')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "49bce64a5893733eb611c270e56266c9423ac8c3045a4a89fa36c393cf7fbb87"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
