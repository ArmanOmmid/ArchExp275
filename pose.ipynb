{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import kornia.geometry.conversions as conversions\n",
    "\n",
    "\n",
    "from torchinfo import summary\n",
    "from models import XSwinFusion \n",
    "from pose_estimation import PoseDataNPZTorch\n",
    "\n",
    "\n",
    "WORKDIR = f\"{os.getcwd()}/..\"\n",
    "DATA_FOLDER = os.path.join(WORKDIR, \"data_folder\")\n",
    "DATASET_NPZ_PATH = os.path.join(DATA_FOLDER, \"dataset_npz\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FCN_ResNet50_Weights.COCO_WITH_VOC_LABELS_V1`. You can also use `weights=FCN_ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Presumed Preloaded NPZ Dataset: /Users/armanommid/Code/CSE/CSE275/HW2/XSwinDiffusion/../data_folder/dataset_npz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "=====================================================================================\n",
       "Layer (type:depth-idx)                                       Param #\n",
       "=====================================================================================\n",
       "XSwinFusion                                                  --\n",
       "├─FCN: 1-1                                                   35,355,328\n",
       "├─PointNet: 1-2                                              622,482\n",
       "├─Sequential: 1-3                                            12,672\n",
       "├─Sequential: 1-4                                            265,088\n",
       "├─Sequential: 1-5                                            3,161\n",
       "├─Sequential: 1-6                                            2,883\n",
       "├─Sequential: 1-7                                            2,865\n",
       "=====================================================================================\n",
       "Total params: 36,264,479\n",
       "Trainable params: 36,260,374\n",
       "Non-trainable params: 4,105\n",
       "====================================================================================="
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples = 1_000\n",
    "resize = (144, 256)\n",
    "aspect_ratio = True\n",
    "margin = 12\n",
    "feature_dims = 64\n",
    "pretrained = True\n",
    "B = 10\n",
    "\n",
    "model = XSwinFusion(feature_dims=feature_dims, resize=resize, pretrained=True)\n",
    "\n",
    "dataset = None\n",
    "dataset = PoseDataNPZTorch(DATASET_NPZ_PATH, samples=samples, \n",
    "                           resize=resize, aspect_ratio=aspect_ratio, margin=margin)\n",
    "dataloader = DataLoader(dataset, batch_size=B, shuffle=True)\n",
    "\n",
    "summary(model, depth=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('zinf', 'z4|x4|y4', 'z2', 'zinf', 'z4|x4|y4', 'z4|x4|y4', 'z2|y2|x4', 'z2|y2|x4', 'z2|x2', 'z4')\n",
      "('z2', 'no', 'z2|x4|y2', 'z2|y2|x4', 'z2|x2', 'z2|x2', 'zinf', 'zinf|x2', 'z2|x2', 'z2|x2')\n",
      "('z2|x2', 'z2|y2|x4', 'x2', 'zinf|x2', 'zinf', 'z2|x2', 'zinf', 'zinf|x2', 'no', 'z2|x2')\n",
      "('zinf', 'zinf|x2', 'z2|y2|x4', 'z2|x2', 'x2', 'zinf|x2', 'z2', 'no', 'zinf|x2', 'zinf')\n",
      "('z2|x2', 'z2', 'z2|y2|x4', 'z2|x2', 'zinf|x2', 'z2|x2', 'z2', 'z2|x2', 'z2', 'no')\n",
      "('xinf', 'z2|x2', 'z2|x2', 'z2|x4|y2', 'z2|x2', 'zinf|x2', 'z2|x2', 'zinf', 'z2', 'z4|x4|y4')\n",
      "('z2|x4|y2', 'zinf|x2', 'z4|x4|y4', 'z2', 'zinf', 'z2', 'z2', 'z4|x4|y4', 'zinf|x2', 'z2|x2')\n",
      "('z4', 'z2|x2', 'z4|x4|y4', 'zinf|x2', 'z2', 'z2|x2', 'zinf|x2', 'z2|y2|x4', 'z2', 'z2')\n",
      "('z2|y2|x4', 'z2', 'z2', 'zinf|x2', 'z2|x2', 'z2', 'zinf|x2', 'z2|x2', 'zinf|x2', 'z2|x2')\n",
      "('zinf|x2', 'z2|y2|x4', 'zinf|x2', 'zinf|x2', 'zinf', 'z2|x2', 'z2|y2|x4', 'zinf', 'z2', 'z2|x2')\n",
      "('zinf|x2', 'z2|x2', 'z4|x4|y4', 'z2', 'zinf|x2', 'z2|x2', 'zinf|x2', 'z2', 'zinf|x2', 'x2')\n",
      "('zinf|x2', 'z2', 'z2|x2', 'z2|x2', 'z2', 'no', 'z2', 'z2', 'z2|x2', 'z2|x2')\n",
      "('z2', 'x2', 'z2|x2', 'z2|x2', 'z2|x2', 'zinf|x2', 'zinf', 'zinf|x2', 'z2', 'zinf|x2')\n",
      "('z2|x2', 'z2|x2', 'z2|y2|x4', 'z2|x2', 'z2|x2', 'zinf', 'z4', 'z2', 'zinf', 'zinf|x2')\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/armanommid/Code/CSE/CSE275/HW2/XSwinDiffusion/pose.ipynb Cell 4\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/armanommid/Code/CSE/CSE275/HW2/XSwinDiffusion/pose.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m points \u001b[39m=\u001b[39m []\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/armanommid/Code/CSE/CSE275/HW2/XSwinDiffusion/pose.ipynb#W3sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfor\u001b[39;00m i, (s, t, c, mi, p, sym) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(dataloader):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/armanommid/Code/CSE/CSE275/HW2/XSwinDiffusion/pose.ipynb#W3sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39mprint\u001b[39m(sym)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/utils/data/dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    632\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    633\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 634\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    635\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    636\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    638\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/utils/data/dataloader.py:678\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    676\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    677\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 678\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    679\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    680\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/Code/CSE/CSE275/HW2/XSwinDiffusion/pose_estimation/pose_data_npz.py:166\u001b[0m, in \u001b[0;36mPoseDataNPZTorch.__getitem__\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m    162\u001b[0m mask \u001b[39m=\u001b[39m scene[\u001b[39m\"\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m==\u001b[39m obj_id\n\u001b[1;32m    163\u001b[0m meta \u001b[39m=\u001b[39m scene[\u001b[39m\"\u001b[39m\u001b[39mmeta\u001b[39m\u001b[39m\"\u001b[39m][()]\n\u001b[0;32m--> 166\u001b[0m (color, depth, mask), scale, translate \u001b[39m=\u001b[39m crop_and_resize_multiple(\n\u001b[1;32m    167\u001b[0m     (color, depth, mask), \n\u001b[1;32m    168\u001b[0m     mask, target_size\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mresize, margin\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmargin, aspect_ratio\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maspect_ratio)\n\u001b[1;32m    170\u001b[0m color \u001b[39m=\u001b[39m color\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39mfloat32) \u001b[39m/\u001b[39m \u001b[39m255\u001b[39m\n\u001b[1;32m    171\u001b[0m depth \u001b[39m=\u001b[39m depth\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39mfloat32) \u001b[39m/\u001b[39m \u001b[39m1000\u001b[39m\n",
      "File \u001b[0;32m~/Code/CSE/CSE275/HW2/XSwinDiffusion/pose_estimation/utils.py:143\u001b[0m, in \u001b[0;36mcrop_and_resize_multiple\u001b[0;34m(feature_maps, mask, target_size, margin, aspect_ratio, mask_fill)\u001b[0m\n\u001b[1;32m    141\u001b[0m new_maps \u001b[39m=\u001b[39m []\n\u001b[1;32m    142\u001b[0m \u001b[39mfor\u001b[39;00m \u001b[39mmap\u001b[39m \u001b[39min\u001b[39;00m feature_maps:\n\u001b[0;32m--> 143\u001b[0m     new_map, s, t \u001b[39m=\u001b[39m crop_and_resize(\u001b[39mmap\u001b[39;49m, mask, target_size\u001b[39m=\u001b[39;49mtarget_size, margin\u001b[39m=\u001b[39;49mmargin, aspect_ratio\u001b[39m=\u001b[39;49maspect_ratio, mask_fill\u001b[39m=\u001b[39;49mmask_fill)\n\u001b[1;32m    144\u001b[0m     new_maps\u001b[39m.\u001b[39mappend(new_map)\n\u001b[1;32m    145\u001b[0m \u001b[39mreturn\u001b[39;00m new_maps, s, t\n",
      "File \u001b[0;32m~/Code/CSE/CSE275/HW2/XSwinDiffusion/pose_estimation/utils.py:81\u001b[0m, in \u001b[0;36mcrop_and_resize\u001b[0;34m(feature_map, mask, target_size, margin, aspect_ratio, mask_fill)\u001b[0m\n\u001b[1;32m     78\u001b[0m     feature_map[mask \u001b[39m==\u001b[39m \u001b[39mFalse\u001b[39;00m] \u001b[39m=\u001b[39m mask_fill\n\u001b[1;32m     80\u001b[0m \u001b[39m# Identify the object's coordinates from the segmentation map\u001b[39;00m\n\u001b[0;32m---> 81\u001b[0m rows, cols \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mwhere(mask)\n\u001b[1;32m     82\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mlen\u001b[39m(rows) \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mlen\u001b[39m(cols):\n\u001b[1;32m     83\u001b[0m     \u001b[39m# Return the original image if no object is found in the segmentation map\u001b[39;00m\n\u001b[1;32m     84\u001b[0m     \u001b[39mreturn\u001b[39;00m feature_map, np\u001b[39m.\u001b[39mones(\u001b[39m3\u001b[39m,)\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mwhere\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "points = []\n",
    "\n",
    "for i, (s, t, c, mi, p, sym) in enumerate(dataloader):\n",
    "    print(sym)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z2|x2\n",
      "['z2', 'x2']\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "linspace() got an unexpected keyword argument 'endpoint'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/armanommid/Code/CSE/CSE275/HW2/XSwinDiffusion/pose.ipynb Cell 5\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/armanommid/Code/CSE/CSE275/HW2/XSwinDiffusion/pose.ipynb#W4sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m             matrices\u001b[39m.\u001b[39mappend(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/armanommid/Code/CSE/CSE275/HW2/XSwinDiffusion/pose.ipynb#W4sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m                 conversions\u001b[39m.\u001b[39mangle_axis_to_rotation_matrix(angle \u001b[39m*\u001b[39m basis[b])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/armanommid/Code/CSE/CSE275/HW2/XSwinDiffusion/pose.ipynb#W4sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m             )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/armanommid/Code/CSE/CSE275/HW2/XSwinDiffusion/pose.ipynb#W4sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m matrices\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/armanommid/Code/CSE/CSE275/HW2/XSwinDiffusion/pose.ipynb#W4sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m enumerate_symmetries(p[\u001b[39m0\u001b[39m], sym[\u001b[39m0\u001b[39m])\n",
      "\u001b[1;32m/Users/armanommid/Code/CSE/CSE275/HW2/XSwinDiffusion/pose.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/armanommid/Code/CSE/CSE275/HW2/XSwinDiffusion/pose.ipynb#W4sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m b \u001b[39m=\u001b[39m sym_n[\u001b[39m0\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/armanommid/Code/CSE/CSE275/HW2/XSwinDiffusion/pose.ipynb#W4sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m n \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(sym_n[\u001b[39m1\u001b[39m]) \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(sym[\u001b[39m1\u001b[39m:]) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39melse\u001b[39;00m inf\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/armanommid/Code/CSE/CSE275/HW2/XSwinDiffusion/pose.ipynb#W4sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m angles \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mlinspace(\u001b[39m0\u001b[39;49m, \u001b[39m2\u001b[39;49m\u001b[39m*\u001b[39;49mtorch\u001b[39m.\u001b[39;49mpi, steps\u001b[39m=\u001b[39;49mn, endpoint\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/armanommid/Code/CSE/CSE275/HW2/XSwinDiffusion/pose.ipynb#W4sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mfor\u001b[39;00m angle \u001b[39min\u001b[39;00m angle:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/armanommid/Code/CSE/CSE275/HW2/XSwinDiffusion/pose.ipynb#W4sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     matrices\u001b[39m.\u001b[39mappend(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/armanommid/Code/CSE/CSE275/HW2/XSwinDiffusion/pose.ipynb#W4sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m         conversions\u001b[39m.\u001b[39mangle_axis_to_rotation_matrix(angle \u001b[39m*\u001b[39m basis[b])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/armanommid/Code/CSE/CSE275/HW2/XSwinDiffusion/pose.ipynb#W4sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     )\n",
      "\u001b[0;31mTypeError\u001b[0m: linspace() got an unexpected keyword argument 'endpoint'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def enumerate_symmetries(R, info, inf=24):\n",
    "    basis = {\"x\" : torch.tensor([1, 0, 0]), \"y\" : torch.tensor([0, 1, 0]), \"z\" : torch.tensor([0, 0, 1])}\n",
    "    matrices = []\n",
    "    if info == \"no\":\n",
    "        return matrices\n",
    "    print(info)\n",
    "    print(info.split(\"|\"))\n",
    "    for sym_n in info[0].split(\"|\"):\n",
    "        b = sym_n[0]\n",
    "        n = int(sym_n[1]) if len(sym[1:]) == 1 else inf\n",
    "        angles = torch.linspace(0, 2*torch.pi, steps=n)\n",
    "        for angle in angle:\n",
    "            matrices.append(\n",
    "                conversions.angle_axis_to_rotation_matrix(angle * basis[b])\n",
    "            )\n",
    "    return matrices\n",
    "\n",
    "\n",
    "\n",
    "enumerate_symmetries(p[0], sym[0])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
