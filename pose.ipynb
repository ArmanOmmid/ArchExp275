{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchinfo import summary\n",
    "from models import XSwinFusion \n",
    "from pose_estimation import PoseDataNPZTorch\n",
    "\n",
    "\n",
    "WORKDIR = f\"{os.getcwd()}/..\"\n",
    "DATA_FOLDER = os.path.join(WORKDIR, \"data_folder\")\n",
    "DATASET_NPZ_PATH = os.path.join(DATA_FOLDER, \"dataset_npz\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 3, 2, 3, 2, 3, 2, 3])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([0, 1, 2, 3, 4, 5])\n",
    "\n",
    "x = x[[2,3, 2,3,2 ,3 ,2 ,3]]\n",
    "x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24, 48, 96]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "embed_dim must be divisible by num_heads",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/armanommid/Code/CSE/CSE275/HW2/XSwinDiffusion/pose.ipynb Cell 3\u001b[0m line \u001b[0;36m7\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/armanommid/Code/CSE/CSE275/HW2/XSwinDiffusion/pose.ipynb#W1sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m margin \u001b[39m=\u001b[39m \u001b[39m12\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/armanommid/Code/CSE/CSE275/HW2/XSwinDiffusion/pose.ipynb#W1sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m feature_dims \u001b[39m=\u001b[39m \u001b[39m384\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/armanommid/Code/CSE/CSE275/HW2/XSwinDiffusion/pose.ipynb#W1sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m fusion \u001b[39m=\u001b[39m XSwinFusion(feature_dims\u001b[39m=\u001b[39mfeature_dims, resize\u001b[39m=\u001b[39mresize)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/armanommid/Code/CSE/CSE275/HW2/XSwinDiffusion/pose.ipynb#W1sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m dataset \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/armanommid/Code/CSE/CSE275/HW2/XSwinDiffusion/pose.ipynb#W1sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m dataset \u001b[39m=\u001b[39m PoseDataNPZTorch(DATASET_NPZ_PATH, samples\u001b[39m=\u001b[39msamples, \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/armanommid/Code/CSE/CSE275/HW2/XSwinDiffusion/pose.ipynb#W1sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m                            resize\u001b[39m=\u001b[39mresize, aspect_ratio\u001b[39m=\u001b[39maspect_ratio, margin\u001b[39m=\u001b[39mmargin)\n",
      "File \u001b[0;32m~/Code/CSE/CSE275/HW2/XSwinDiffusion/models/xswin_fusion.py:31\u001b[0m, in \u001b[0;36mXSwinFusion.__init__\u001b[0;34m(self, feature_dims, swin_embed_dims, resize, xswin_weights, **kwargs)\u001b[0m\n\u001b[1;32m     28\u001b[0m num_heads \u001b[39m=\u001b[39m [head\u001b[39m*\u001b[39m(\u001b[39m2\u001b[39m\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mi) \u001b[39mfor\u001b[39;00m i, _ \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(depths)]\n\u001b[1;32m     29\u001b[0m \u001b[39mprint\u001b[39m(num_heads)\n\u001b[0;32m---> 31\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msegment_net \u001b[39m=\u001b[39m XNetSwinTransformer(patch_size\u001b[39m=\u001b[39;49mpatch_size, embed_dim\u001b[39m=\u001b[39;49mswin_embed_dims, \n\u001b[1;32m     32\u001b[0m                     depths\u001b[39m=\u001b[39;49mdepths, num_heads\u001b[39m=\u001b[39;49mnum_heads, window_size\u001b[39m=\u001b[39;49mwindow_size, \n\u001b[1;32m     33\u001b[0m                     num_classes\u001b[39m=\u001b[39;49mfeature_dims, global_stages\u001b[39m=\u001b[39;49mglobal_stages, \n\u001b[1;32m     34\u001b[0m                     input_size\u001b[39m=\u001b[39;49mresize, final_downsample\u001b[39m=\u001b[39;49mfinal_downsample, \n\u001b[1;32m     35\u001b[0m                     residual_cross_attention\u001b[39m=\u001b[39;49mresidual_cross_attention,\n\u001b[1;32m     36\u001b[0m                     smooth_conv\u001b[39m=\u001b[39;49msmooth_conv, weights\u001b[39m=\u001b[39;49mxswin_weights,\n\u001b[1;32m     37\u001b[0m                    )\n\u001b[1;32m     39\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpoint_net \u001b[39m=\u001b[39m PointNet(out_channels\u001b[39m=\u001b[39mfeature_dims, embed_dim\u001b[39m=\u001b[39mfeature_dims)\n\u001b[1;32m     41\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mglobal_net \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mSequential(\n\u001b[1;32m     42\u001b[0m     nn\u001b[39m.\u001b[39mConv1d(feature_dims\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m, feature_dims, \u001b[39m1\u001b[39m),\n\u001b[1;32m     43\u001b[0m     nn\u001b[39m.\u001b[39mBatchNorm1d(feature_dims),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     48\u001b[0m     LambdaModule(\u001b[39mlambda\u001b[39;00m x: torch\u001b[39m.\u001b[39mmean(x, \u001b[39m2\u001b[39m, keepdim\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)) \u001b[39m# Average Pooling\u001b[39;00m\n\u001b[1;32m     49\u001b[0m )\n",
      "File \u001b[0;32m~/Code/CSE/CSE275/HW2/XSwinDiffusion/models/xswin.py:131\u001b[0m, in \u001b[0;36mXNetSwinTransformer.__init__\u001b[0;34m(self, patch_size, embed_dim, depths, num_heads, window_size, mlp_ratio, dropout, attention_dropout, stochastic_depth_prob, num_classes, norm_layer, global_stages, input_size, final_downsample, residual_cross_attention, smooth_conv, weights)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmiddle : List[nn\u001b[39m.\u001b[39mModule] \u001b[39m=\u001b[39m []\n\u001b[1;32m    129\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m((global_stages)):\n\u001b[1;32m    130\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmiddle\u001b[39m.\u001b[39mappend(\n\u001b[0;32m--> 131\u001b[0m         ViTEncoderBlock(\n\u001b[1;32m    132\u001b[0m             num_heads \u001b[39m=\u001b[39;49m num_heads[\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m], \u001b[39m# Use number of heads as final Swin Encoder Block\u001b[39;49;00m\n\u001b[1;32m    133\u001b[0m             hidden_dim \u001b[39m=\u001b[39;49m middle_stage_features,\n\u001b[1;32m    134\u001b[0m             mlp_dim \u001b[39m=\u001b[39;49m \u001b[39mint\u001b[39;49m(middle_stage_features \u001b[39m*\u001b[39;49m mlp_ratio),\n\u001b[1;32m    135\u001b[0m             dropout \u001b[39m=\u001b[39;49m dropout,\n\u001b[1;32m    136\u001b[0m             attention_dropout \u001b[39m=\u001b[39;49m attention_dropout,\n\u001b[1;32m    137\u001b[0m             norm_layer \u001b[39m=\u001b[39;49m norm_layer,\n\u001b[1;32m    138\u001b[0m         )\n\u001b[1;32m    139\u001b[0m     )\n\u001b[1;32m    140\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmiddle \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mSequential(\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmiddle) \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmiddle) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39melse\u001b[39;00m nn\u001b[39m.\u001b[39mIdentity()\n\u001b[1;32m    142\u001b[0m \u001b[39m################################################\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[39m# DECODER\u001b[39;00m\n\u001b[1;32m    144\u001b[0m \u001b[39m################################################\u001b[39;00m\n",
      "File \u001b[0;32m~/Code/CSE/CSE275/HW2/XSwinDiffusion/models/modules/normal/vit_block.py:27\u001b[0m, in \u001b[0;36mViTEncoderBlock.__init__\u001b[0;34m(self, num_heads, hidden_dim, mlp_dim, dropout, attention_dropout, norm_layer)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[39m# Attention block\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mln_1 \u001b[39m=\u001b[39m norm_layer(hidden_dim)\n\u001b[0;32m---> 27\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mself_attention \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39;49mMultiheadAttention(hidden_dim, num_heads, dropout\u001b[39m=\u001b[39;49mattention_dropout, batch_first\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     28\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mDropout(dropout)\n\u001b[1;32m     30\u001b[0m \u001b[39m# MLP block\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/activation.py:966\u001b[0m, in \u001b[0;36mMultiheadAttention.__init__\u001b[0;34m(self, embed_dim, num_heads, dropout, bias, add_bias_kv, add_zero_attn, kdim, vdim, batch_first, device, dtype)\u001b[0m\n\u001b[1;32m    964\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_first \u001b[39m=\u001b[39m batch_first\n\u001b[1;32m    965\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhead_dim \u001b[39m=\u001b[39m embed_dim \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m num_heads\n\u001b[0;32m--> 966\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhead_dim \u001b[39m*\u001b[39m num_heads \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membed_dim, \u001b[39m\"\u001b[39m\u001b[39membed_dim must be divisible by num_heads\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    968\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_qkv_same_embed_dim:\n\u001b[1;32m    969\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mq_proj_weight \u001b[39m=\u001b[39m Parameter(torch\u001b[39m.\u001b[39mempty((embed_dim, embed_dim), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfactory_kwargs))\n",
      "\u001b[0;31mAssertionError\u001b[0m: embed_dim must be divisible by num_heads"
     ]
    }
   ],
   "source": [
    "samples = 10_000\n",
    "resize = (432, 768)\n",
    "aspect_ratio = True\n",
    "margin = 12\n",
    "feature_dims = 384\n",
    "\n",
    "fusion = XSwinFusion(feature_dims=feature_dims, resize=resize)\n",
    "\n",
    "dataset = None\n",
    "dataset = PoseDataNPZTorch(DATASET_NPZ_PATH, samples=samples, \n",
    "                           resize=resize, aspect_ratio=aspect_ratio, margin=margin)\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "\n",
    "summary(fusion, depth=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 10000, 3]) torch.Size([2, 3, 432, 768]) torch.Size([2, 432, 768])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [256, 3, 1], expected input[2, 256, 10000] to have 3 channels, but got 256 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/armanommid/Code/CSE/CSE275/HW2/XSwinDiffusion/pose.ipynb Cell 4\u001b[0m line \u001b[0;36m7\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/armanommid/Code/CSE/CSE275/HW2/XSwinDiffusion/pose.ipynb#W4sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfor\u001b[39;00m i, (s, t, c, d, mi, p) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(dataloader):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/armanommid/Code/CSE/CSE275/HW2/XSwinDiffusion/pose.ipynb#W4sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39mprint\u001b[39m(t\u001b[39m.\u001b[39mshape, c\u001b[39m.\u001b[39mshape, d\u001b[39m.\u001b[39mshape)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/armanommid/Code/CSE/CSE275/HW2/XSwinDiffusion/pose.ipynb#W4sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     rgb, pcd, transforms \u001b[39m=\u001b[39m fusion(t, c, mi)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/armanommid/Code/CSE/CSE275/HW2/XSwinDiffusion/pose.ipynb#W4sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39mif\u001b[39;00m i \u001b[39m==\u001b[39m \u001b[39m3\u001b[39m: \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/armanommid/Code/CSE/CSE275/HW2/XSwinDiffusion/pose.ipynb#W4sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39m0\u001b[39m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Code/CSE/CSE275/HW2/XSwinDiffusion/models/xswin_fusion.py:72\u001b[0m, in \u001b[0;36mXSwinFusion.forward\u001b[0;34m(self, pcd, rgb, mask_indices)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, pcd, rgb, mask_indices):\n\u001b[1;32m     70\u001b[0m     rgb \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msegment_net(rgb)\n\u001b[0;32m---> 72\u001b[0m     pcd, transforms \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpoint_net(pcd)\n\u001b[1;32m     74\u001b[0m     rgb \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mpermute(rgb, (\u001b[39m0\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m1\u001b[39m)) \u001b[39m# B C H W -> B H W C (channel last for masking)\u001b[39;00m\n\u001b[1;32m     76\u001b[0m     batch_indices \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marange(pcd\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m))[:, \u001b[39mNone\u001b[39;00m]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Code/CSE/CSE275/HW2/XSwinDiffusion/models/pointnet.py:115\u001b[0m, in \u001b[0;36mPointNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    112\u001b[0m T1 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_tnet(x)\n\u001b[1;32m    113\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpermute(torch\u001b[39m.\u001b[39mbmm(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpermute(x), T1))\n\u001b[0;32m--> 115\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv1(x)\n\u001b[1;32m    117\u001b[0m T2 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeature_tnet(x)\n\u001b[1;32m    118\u001b[0m features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpermute(torch\u001b[39m.\u001b[39mbmm(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpermute(x), T2))\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/conv.py:313\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 313\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/conv.py:309\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    306\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv1d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    307\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    308\u001b[0m                     _single(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> 309\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv1d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    310\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [256, 3, 1], expected input[2, 256, 10000] to have 3 channels, but got 256 channels instead"
     ]
    }
   ],
   "source": [
    "points = []\n",
    "\n",
    "for i, (s, t, c, d, mi, p) in enumerate(dataloader):\n",
    "\n",
    "    print(t.shape, c.shape, d.shape)\n",
    "\n",
    "    rgb, pcd, transforms = fusion(t, c, mi)\n",
    "\n",
    "\n",
    "    if i == 3: \n",
    "        assert 0\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
