{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import kornia.geometry.conversions as conversions\n",
    "\n",
    "\n",
    "from torchinfo import summary\n",
    "from models import XSwinFusion \n",
    "from pose_estimation import PoseDataNPZTorch\n",
    "\n",
    "\n",
    "WORKDIR = f\"{os.getcwd()}/..\"\n",
    "DATA_FOLDER = os.path.join(WORKDIR, \"data_folder\")\n",
    "DATASET_NPZ_PATH = os.path.join(DATA_FOLDER, \"dataset_npz\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 1.],\n",
      "        [0., 0., 0., 1.],\n",
      "        [0., 0., 0., 1.],\n",
      "        [0., 0., 0., 1.]])\n",
      "tensor([[[-1.,  0.,  0.],\n",
      "         [ 0., -1.,  0.],\n",
      "         [ 0.,  0.,  1.]],\n",
      "\n",
      "        [[-1.,  0.,  0.],\n",
      "         [ 0., -1.,  0.],\n",
      "         [ 0.,  0.,  1.]],\n",
      "\n",
      "        [[-1.,  0.,  0.],\n",
      "         [ 0., -1.,  0.],\n",
      "         [ 0.,  0.,  1.]],\n",
      "\n",
      "        [[-1.,  0.,  0.],\n",
      "         [ 0., -1.,  0.],\n",
      "         [ 0.,  0.,  1.]]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([0, 0, 0, 1]).float()\n",
    "x = torch.stack((x, x, x, x))\n",
    "x = torch.nn.functional.normalize(R, p=2, dim=-1)\n",
    "print(x)\n",
    "x = conversions.quaternion_to_rotation_matrix(x)\n",
    "print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FCN_ResNet50_Weights.COCO_WITH_VOC_LABELS_V1`. You can also use `weights=FCN_ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Presumed Preloaded NPZ Dataset: /Users/armanommid/Code/CSE/CSE275/HW2/XSwinDiffusion/../data_folder/dataset_npz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "=====================================================================================\n",
       "Layer (type:depth-idx)                                       Param #\n",
       "=====================================================================================\n",
       "XSwinFusion                                                  --\n",
       "├─FCN: 1-1                                                   35,355,328\n",
       "├─PointNet: 1-2                                              622,482\n",
       "├─Sequential: 1-3                                            12,672\n",
       "├─Sequential: 1-4                                            265,088\n",
       "├─Sequential: 1-5                                            3,161\n",
       "├─Sequential: 1-6                                            2,883\n",
       "├─Sequential: 1-7                                            2,865\n",
       "=====================================================================================\n",
       "Total params: 36,264,479\n",
       "Trainable params: 36,260,374\n",
       "Non-trainable params: 4,105\n",
       "====================================================================================="
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples = 1_000\n",
    "resize = (144, 256)\n",
    "aspect_ratio = True\n",
    "margin = 12\n",
    "feature_dims = 64\n",
    "pretrained = True\n",
    "\n",
    "model = XSwinFusion(num_points=samples, feature_dims=feature_dims, resize=resize, pretrained=True)\n",
    "\n",
    "dataset = None\n",
    "dataset = PoseDataNPZTorch(DATASET_NPZ_PATH, samples=samples, \n",
    "                           resize=resize, aspect_ratio=aspect_ratio, margin=margin)\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "\n",
    "summary(model, depth=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 3]) torch.Size([3, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 1.],\n",
       "        [0., 1., 0., 1.],\n",
       "        [0., 0., 1., 1.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R = torch.eye(3)\n",
    "T = torch.ones((3, 1))\n",
    "print(R.shape, T.shape)\n",
    "torch.cat((R, T), dim=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1000, 3])\n",
      "torch.Size([2, 1000, 3])\n",
      "torch.Size([2, 3, 4])\n",
      "torch.Size([2, 1000, 3])\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/armanommid/Code/CSE/CSE275/HW2/XSwinDiffusion/pose.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/armanommid/Code/CSE/CSE275/HW2/XSwinDiffusion/pose.ipynb#W4sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mprint\u001b[39m(x\u001b[39m.\u001b[39mshape)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/armanommid/Code/CSE/CSE275/HW2/XSwinDiffusion/pose.ipynb#W4sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39mif\u001b[39;00m i \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m: \n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/armanommid/Code/CSE/CSE275/HW2/XSwinDiffusion/pose.ipynb#W4sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39m0\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "points = []\n",
    "\n",
    "for i, (s, t, c, mi, p) in enumerate(dataloader):\n",
    "\n",
    "    x, transforms = model(t, c, mi)\n",
    "    print(s.shape)\n",
    "    print(t.shape)\n",
    "    print(x.shape)\n",
    "\n",
    "    R = x[:, :, :3]\n",
    "    T = x[:, :, 3]\n",
    "\n",
    "    x = torch.bmm(s, R.transpose(-2, -1)) + T.unsqueeze(-2)\n",
    "    print(x.shape)\n",
    "\n",
    "    if i == 0: \n",
    "        assert 0\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
