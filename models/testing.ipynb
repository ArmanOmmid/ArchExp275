{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from swin import SwinTransformer, _patch_expanding_pad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "*A, B= 1, 2\n",
    "A\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4, 1, 1, 1, 1, 2, 2, 2, 2,\n",
      "         3, 3, 3, 3, 4, 4, 4, 4],\n",
      "        [1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4, 1, 1, 1, 1, 2, 2, 2, 2,\n",
      "         3, 3, 3, 3, 4, 4, 4, 4],\n",
      "        [1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4, 1, 1, 1, 1, 2, 2, 2, 2,\n",
      "         3, 3, 3, 3, 4, 4, 4, 4],\n",
      "        [1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4, 1, 1, 1, 1, 2, 2, 2, 2,\n",
      "         3, 3, 3, 3, 4, 4, 4, 4]])\n",
      "torch.Size([1, 8, 8, 4])\n",
      "tensor([4, 4, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([\n",
    "    [1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4],\n",
    "    [1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4],\n",
    "    [1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4],\n",
    "    [1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4],\n",
    "])\n",
    "\n",
    "print(torch.cat((x, x), dim=-1))\n",
    "\n",
    "x = torch.stack((x, x, x, x))\n",
    "\n",
    "# x = x.reshape(2, 2, -1)\n",
    "x = x.unsqueeze(0)\n",
    "\n",
    "x = _patch_expanding_pad(x)\n",
    "\n",
    "print(x.shape)\n",
    "\n",
    "print(x[0][1][3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 128, 128])\n",
      "torch.Size([1, 32, 32, 64])\n",
      ".////\n",
      "torch.Size([1, 8, 8, 256])\n",
      "torch.Size([1, 8, 8, 256])\n",
      "torch.Size([1, 8, 8, 256])\n",
      ".////\n",
      "torch.Size([1, 8, 8, 256])\n",
      "torch.Size([1, 16, 16, 128])\n",
      "torch.Size([1, 16, 16, 128])\n",
      ".////\n",
      "torch.Size([1, 32, 32, 128])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1024x128 and 256x768)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/armanommid/Code/CSE/CSE275/ArchExp/ArchExp275/models/testing.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/armanommid/Code/CSE/CSE275/ArchExp/ArchExp275/models/testing.ipynb#W1sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrandn((\u001b[39m1\u001b[39m, \u001b[39m3\u001b[39m, IMG, IMG))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/armanommid/Code/CSE/CSE275/ArchExp/ArchExp275/models/testing.ipynb#W1sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mprint\u001b[39m(x\u001b[39m.\u001b[39mshape)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/armanommid/Code/CSE/CSE275/ArchExp/ArchExp275/models/testing.ipynb#W1sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m y \u001b[39m=\u001b[39m swin(x)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/armanommid/Code/CSE/CSE275/ArchExp/ArchExp275/models/testing.ipynb#W1sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39mprint\u001b[39m(y\u001b[39m.\u001b[39mshape)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/armanommid/Code/CSE/CSE275/ArchExp/ArchExp275/models/testing.ipynb#W1sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mprint\u001b[39m(swin)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Code/CSE/CSE275/ArchExp/ArchExp275/models/swin.py:281\u001b[0m, in \u001b[0;36mSwinTransformer.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[39mprint\u001b[39m(x\u001b[39m.\u001b[39mshape)\n\u001b[1;32m    280\u001b[0m \u001b[39mif\u001b[39;00m i \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfinal_downsample:\n\u001b[0;32m--> 281\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdecoder[i](x) \u001b[39m# Upsample (PatchExpand)\u001b[39;00m\n\u001b[1;32m    283\u001b[0m residual \u001b[39m=\u001b[39m residuals[i_residual]\n\u001b[1;32m    284\u001b[0m \u001b[39mprint\u001b[39m(x\u001b[39m.\u001b[39mshape)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torchvision/models/swin_transformer.py:503\u001b[0m, in \u001b[0;36mSwinTransformerBlockV2.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor):\n\u001b[1;32m    501\u001b[0m     \u001b[39m# Here is the difference, we apply norm after the attention in V2.\u001b[39;00m\n\u001b[1;32m    502\u001b[0m     \u001b[39m# In V1 we applied norm before the attention.\u001b[39;00m\n\u001b[0;32m--> 503\u001b[0m     x \u001b[39m=\u001b[39m x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstochastic_depth(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm1(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattn(x)))\n\u001b[1;32m    504\u001b[0m     x \u001b[39m=\u001b[39m x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstochastic_depth(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm2(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmlp(x)))\n\u001b[1;32m    505\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torchvision/models/swin_transformer.py:384\u001b[0m, in \u001b[0;36mShiftedWindowAttentionV2.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    378\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m    379\u001b[0m \u001b[39m    x (Tensor): Tensor with layout of [B, H, W, C]\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \u001b[39mReturns:\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[39m    Tensor with same layout as input, i.e. [B, H, W, C]\u001b[39;00m\n\u001b[1;32m    382\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    383\u001b[0m relative_position_bias \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_relative_position_bias()\n\u001b[0;32m--> 384\u001b[0m \u001b[39mreturn\u001b[39;00m shifted_window_attention(\n\u001b[1;32m    385\u001b[0m     x,\n\u001b[1;32m    386\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mqkv\u001b[39m.\u001b[39;49mweight,\n\u001b[1;32m    387\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mproj\u001b[39m.\u001b[39;49mweight,\n\u001b[1;32m    388\u001b[0m     relative_position_bias,\n\u001b[1;32m    389\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwindow_size,\n\u001b[1;32m    390\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_heads,\n\u001b[1;32m    391\u001b[0m     shift_size\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mshift_size,\n\u001b[1;32m    392\u001b[0m     attention_dropout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattention_dropout,\n\u001b[1;32m    393\u001b[0m     dropout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout,\n\u001b[1;32m    394\u001b[0m     qkv_bias\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mqkv\u001b[39m.\u001b[39;49mbias,\n\u001b[1;32m    395\u001b[0m     proj_bias\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mproj\u001b[39m.\u001b[39;49mbias,\n\u001b[1;32m    396\u001b[0m     logit_scale\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlogit_scale,\n\u001b[1;32m    397\u001b[0m     training\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining,\n\u001b[1;32m    398\u001b[0m )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torchvision/models/swin_transformer.py:179\u001b[0m, in \u001b[0;36mshifted_window_attention\u001b[0;34m(input, qkv_weight, proj_weight, relative_position_bias, window_size, num_heads, shift_size, attention_dropout, dropout, qkv_bias, proj_bias, logit_scale, training)\u001b[0m\n\u001b[1;32m    177\u001b[0m     length \u001b[39m=\u001b[39m qkv_bias\u001b[39m.\u001b[39mnumel() \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m \u001b[39m3\u001b[39m\n\u001b[1;32m    178\u001b[0m     qkv_bias[length : \u001b[39m2\u001b[39m \u001b[39m*\u001b[39m length]\u001b[39m.\u001b[39mzero_()\n\u001b[0;32m--> 179\u001b[0m qkv \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39;49mlinear(x, qkv_weight, qkv_bias)\n\u001b[1;32m    180\u001b[0m qkv \u001b[39m=\u001b[39m qkv\u001b[39m.\u001b[39mreshape(x\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m), x\u001b[39m.\u001b[39msize(\u001b[39m1\u001b[39m), \u001b[39m3\u001b[39m, num_heads, C \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m num_heads)\u001b[39m.\u001b[39mpermute(\u001b[39m2\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m4\u001b[39m)\n\u001b[1;32m    181\u001b[0m q, k, v \u001b[39m=\u001b[39m qkv[\u001b[39m0\u001b[39m], qkv[\u001b[39m1\u001b[39m], qkv[\u001b[39m2\u001b[39m]\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1024x128 and 256x768)"
     ]
    }
   ],
   "source": [
    "patch_size = [4, 4]\n",
    "embed_dim = 64\n",
    "depths = [2, 2, 2]\n",
    "num_heads = [4, 4, 4]\n",
    "window_size = [4, 4]\n",
    "num_classes = 1\n",
    "\n",
    "\n",
    "swin = SwinTransformer(patch_size, embed_dim, depths, num_heads, window_size, num_classes=num_classes)\n",
    "\n",
    "IMG = 128\n",
    "x = torch.randn((1, 3, IMG, IMG))\n",
    "print(x.shape)\n",
    "\n",
    "y = swin(x)\n",
    "print(y.shape)\n",
    "\n",
    "print(swin)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
